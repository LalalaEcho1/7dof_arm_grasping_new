#!/usr/bin/env python3
"""
åˆ†é˜¶æ®µè®­ç»ƒè„šæœ¬ - æ¸è¿›å¼æé«˜æŠ“å–éš¾åº¦
"""

import os
import yaml
from stable_baselines3 import SAC
from stable_baselines3.common.callbacks import CheckpointCallback, BaseCallback
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize
from envs.seven_dof_arm import SevenDOFArmEnv

class EpisodeLoggerCallback(BaseCallback):
    def _on_step(self) -> bool:
        infos = self.locals.get('infos', [])
        for info in infos:
            if 'episode' in info:
                ep_r = info['episode']['r']
                ep_l = info['episode']['l']
                print(f"[Episode] reward: {ep_r:.2f}, length: {ep_l}")
        
        # æ›´æ–°è¯¾ç¨‹å­¦ä¹ è¿›åº¦
        if hasattr(self, '_training_env') and hasattr(self._training_env, 'envs'):
            progress = self.num_timesteps / self._total_timesteps
            for env in self._training_env.envs:
                if hasattr(env, 'env') and hasattr(env.env, 'set_training_progress'):
                    env.env.set_training_progress(progress)
        
        return True

class SuccessRateCallback(BaseCallback):
    """ç›‘æ§æˆåŠŸç‡çš„å›è°ƒ"""
    def __init__(self, eval_freq=1000, verbose=1):
        super().__init__(verbose)
        self.eval_freq = eval_freq
        self.success_count = 0
        self.total_episodes = 0
        
    def _on_step(self) -> bool:
        if self.n_calls % self.eval_freq == 0:
            # è¯„ä¼°å½“å‰æˆåŠŸç‡
            success_rate = self._evaluate_success_rate()
            print(f"[Step {self.n_calls}] å½“å‰æˆåŠŸç‡: {success_rate:.1%}")
            
            # å¦‚æœæˆåŠŸç‡è¶³å¤Ÿé«˜ï¼Œå¯ä»¥è°ƒæ•´æˆåŠŸæ¡ä»¶
            if success_rate > 0.8 and hasattr(self.training_env, 'envs'):
                self._adjust_success_condition()
        
        return True
    
    def _evaluate_success_rate(self):
        """è¯„ä¼°æˆåŠŸç‡"""
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„è¯„ä¼°é€»è¾‘
        return self.success_count / max(self.total_episodes, 1)
    
    def _adjust_success_condition(self):
        """è°ƒæ•´æˆåŠŸæ¡ä»¶"""
        print("ğŸ¯ æˆåŠŸç‡è¶…è¿‡80%ï¼Œå»ºè®®è°ƒæ•´æˆåŠŸæ¡ä»¶ï¼")
        # è¿™é‡Œå¯ä»¥åŠ¨æ€è°ƒæ•´ç¯å¢ƒçš„æˆåŠŸæ¡ä»¶

def make_env(render_mode=None):
    def _init():
        env = SevenDOFArmEnv(render_mode=render_mode, model_path='franka/panda.xml')
        env = Monitor(env)
        return env
    return _init

def train_stage(stage_name, timesteps, success_threshold=None):
    """åˆ†é˜¶æ®µè®­ç»ƒ"""
    print(f"\nğŸš€ å¼€å§‹ {stage_name} è®­ç»ƒ...")
    
    # åˆ›å»ºç¯å¢ƒ
    env = DummyVecEnv([make_env(render_mode=None)])
    env = VecNormalize(env, norm_obs=True, norm_reward=False)
    
    # å¦‚æœæŒ‡å®šäº†æˆåŠŸé˜ˆå€¼ï¼Œè°ƒæ•´ç¯å¢ƒ
    if success_threshold:
        for env_wrapper in env.envs:
            if hasattr(env_wrapper.env, 'success_threshold'):
                env_wrapper.env.success_threshold = success_threshold
                print(f"è®¾ç½®æˆåŠŸé˜ˆå€¼: {success_threshold}")
    
    # åˆ›å»ºæ¨¡å‹
    model = SAC(
        "MlpPolicy",
        env,
        device='cuda',
        verbose=2,
        learning_rate=1e-4,
        buffer_size=200000,
        batch_size=512,
        gamma=0.995,
        tau=0.01,
        ent_coef='auto',
        tensorboard_log="./logs/",
        policy_kwargs={"net_arch": [512, 512, 256]},
        target_update_interval=1,
    )
    
    # å›è°ƒå‡½æ•°
    callback = EpisodeLoggerCallback()
    callback._training_env = env
    callback._total_timesteps = timesteps
    
    success_callback = SuccessRateCallback(eval_freq=1000)
    
    checkpoint_callback = CheckpointCallback(
        save_freq=timesteps // 4,  # ä¿å­˜4æ¬¡
        save_path=f"./models/{stage_name}/",
        name_prefix="sac_7dof"
    )
    
    # å¼€å§‹è®­ç»ƒ
    model.learn(
        total_timesteps=timesteps,
        callback=[checkpoint_callback, callback, success_callback],
        tb_log_name=stage_name,
        log_interval=100
    )
    
    # ä¿å­˜æ¨¡å‹
    model.save(f"./models/{stage_name}_final")
    env.save(f"./models/{stage_name}_vec_normalize.pkl")
    
    env.close()
    print(f"âœ… {stage_name} è®­ç»ƒå®Œæˆï¼")
    
    return model

def main():
    """ä¸»è®­ç»ƒæµç¨‹"""
    os.makedirs("./models/", exist_ok=True)
    os.makedirs("./logs/", exist_ok=True)
    
    print("ğŸ¯ å¼€å§‹åˆ†é˜¶æ®µæŠ“å–è®­ç»ƒ...")
    
    # é˜¶æ®µ1ï¼šæ¥è¿‘è®­ç»ƒ (è·ç¦»<0.5m)
    print("\n" + "="*50)
    print("é˜¶æ®µ1ï¼šæ¥è¿‘è®­ç»ƒ")
    print("ç›®æ ‡ï¼šå­¦ä¼šæ¥è¿‘ç›®æ ‡ç‰©ä½“")
    print("æˆåŠŸæ¡ä»¶ï¼šè·ç¦» < 0.5m")
    print("="*50)
    train_stage("stage1_approach", timesteps=50000, success_threshold=0.5)
    
    # é˜¶æ®µ2ï¼šç²¾ç¡®æ¥è¿‘ (è·ç¦»<0.3m)
    print("\n" + "="*50)
    print("é˜¶æ®µ2ï¼šç²¾ç¡®æ¥è¿‘")
    print("ç›®æ ‡ï¼šæ›´ç²¾ç¡®åœ°æ¥è¿‘ç›®æ ‡")
    print("æˆåŠŸæ¡ä»¶ï¼šè·ç¦» < 0.3m")
    print("="*50)
    train_stage("stage2_precise", timesteps=50000, success_threshold=0.3)
    
    # é˜¶æ®µ3ï¼šæ¥è§¦è®­ç»ƒ (å•æŒ‡æ¥è§¦)
    print("\n" + "="*50)
    print("é˜¶æ®µ3ï¼šæ¥è§¦è®­ç»ƒ")
    print("ç›®æ ‡ï¼šå­¦ä¼šæ¥è§¦ç›®æ ‡ç‰©ä½“")
    print("æˆåŠŸæ¡ä»¶ï¼šå•æŒ‡æ¥è§¦")
    print("="*50)
    train_stage("stage3_contact", timesteps=50000, success_threshold="contact")
    
    # é˜¶æ®µ4ï¼šæŠ“å–è®­ç»ƒ (åŒæŒ‡æ¥è§¦)
    print("\n" + "="*50)
    print("é˜¶æ®µ4ï¼šæŠ“å–è®­ç»ƒ")
    print("ç›®æ ‡ï¼šå­¦ä¼šæŠ“å–ç›®æ ‡ç‰©ä½“")
    print("æˆåŠŸæ¡ä»¶ï¼šåŒæŒ‡æ¥è§¦")
    print("="*50)
    train_stage("stage4_grasp", timesteps=50000, success_threshold="grasp")
    
    # é˜¶æ®µ5ï¼šæŠ¬å‡è®­ç»ƒ (æŠ“å–+æŠ¬å‡)
    print("\n" + "="*50)
    print("é˜¶æ®µ5ï¼šæŠ¬å‡è®­ç»ƒ")
    print("ç›®æ ‡ï¼šå­¦ä¼šæŠ“å–å¹¶æŠ¬å‡ç‰©ä½“")
    print("æˆåŠŸæ¡ä»¶ï¼šåŒæŒ‡æ¥è§¦ + æŠ¬å‡")
    print("="*50)
    train_stage("stage5_lift", timesteps=50000, success_threshold="lift")
    
    print("\nğŸ‰ æ‰€æœ‰é˜¶æ®µè®­ç»ƒå®Œæˆï¼")

if __name__ == "__main__":
    main()
